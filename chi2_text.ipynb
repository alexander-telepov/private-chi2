{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Private Hypothesis Testing: Chi-Square Tests\n",
    "\n",
    "The article is written by Marco Gaboardi and Ryan Rogers.\n",
    "\n",
    "The students' project is prepared by:\n",
    "- Alexander Telepov\n",
    "- Maksim Pankratov\n",
    "- Julia Moroz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $$Problem\\, statement$$\n",
    "  Hypothesis testing was developed for scientific and survey data, but today it is also an essential tool to test models over collections of social network, mobile, and crowdsourced data. Collected data samples may contain highly sensitive information about the subjects, and the privacy of individuals can be compromised when the results of a data analysis are released. The authors explored the design of private hypothesis tests in the local model, where each data entry is perturbed to ensure the privacy of each participant. Specifically, they analyzed locally private chi-square tests for goodness of fit and independence testing. The authors presented seven new algorithms (some of them are: Locally Private GOF Test, Generalized Randomized Response,  Local DP GOF Test, Bit Flip Local Randomizer) for testing hypotheses on private data that was noised."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](pictures/problem_statement.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authors proposed local private tests for Hypotesis about parameter of Multinomial distribution and independece of samples from 2 Multinomial distributions because there were not local differential private test for multinomial distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authors prove that proposed algorytms are $\\rho-Lz$CDP,  $\\varepsilon$-LDP. They also proved theorems about assimptotic distribution of considered statistics under some settings $H_0$ and $H_1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $$Algorithms$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](pictures/algorithms.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All algorithm utilize corresponding theorems about convergence of proposed statistics in distribution to $\\chi^2$ under $H_0: p=p_0$ or non-central $\\chi^2$ under $H_1:p=p_0 + \\frac{\\Delta}{\\sqrt{n}}, \\;1^T \\Delta=0$.\n",
    "\n",
    "All algorithms work with perturbed data:\n",
    "- LocalNoiseGOFT takes data with added predifened noise\n",
    "- LocalGenRRGOF takes data where in each sample indicator position was changed with distribution which depends on sample. \n",
    "- LocalBitFlipGOF takes data where in each sample each component was changed with distribution which depends on component."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complexity of algorithms:\n",
    "- Non-Private \n",
    "    $\\mathcal{O}(nd)$\n",
    "- LocalNoiseGOFT\n",
    "    - (a) Gauss Noise\n",
    "    $\\mathcal{O}(nd + d^2 + dq_{Gauss})$, $q_{Gauss}$ here is the complexity of generating one number from gaussin distribution. The most expensive operation - matvec with $\\Sigma$ - $\\mathcal{O}(d^2)$ and calculation of $\\Sigma^{-1}$, since matvec with $\\prod$ : $\\prod x = x - \\bar{x}$ calculated in $\\mathcal{O}(d)$,  $\\Sigma^{-1}$ can be computed via Sherman-Morisson formula with $\\mathcal{O}(d^2)$ (because $A$ in Sherman-Morisson formula diagonal here - diag($p^0 + \\sigma$)).\n",
    "    - (b) Lalplace Noise\n",
    "    $\\mathcal{O}(md^2 + mdnq_{Laplace})$ - similar to (a), but procedure is repeated $m$ times and in each step we need to generate $nd$ numbers from Laplace distribution.\n",
    "- LocalGenRRGOF\n",
    "    $\\mathcal{O}(nd + nq_{Multinomial(d)})$, where $q_{Multinomial(d)}$ - complexity of generation sample from multinomial distribuion with size d. \n",
    "- LocalBitFlipGOF\n",
    "    $\\mathcal{O}(ndq_{Bernulli} + d^2)$, where $q_{Bernulli}$ - complexity of generation sample from Bernulli distribuion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $$Experiments$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We made comparison of empirical power among the classical non-private test and the local private tests: LocalNoiseGOF with Laplace noise, LocalGenRRGOF, and LocalBitFlipGOF.\n",
    "\n",
    "Experiments setup:\n",
    "$H_0: Multinomial(p_0), \\; H_1: Multinomial(p_1), p_1 = p_0 + \\eta (1, -1, ..., 1, -1)$\n",
    "\n",
    "$ d $= 4, $\\eta$ = 0.01, $\\varepsilon$ = {1, 2, 4}.\n",
    "\n",
    "It was performed 50 tests to estimate test power(in the article it was performed 1000 simulations). Our calculations look very close with those presented in the article. <br>\n",
    "Results we got: for any $\\varepsilon$  privacy parameter LocalNoiseGOF < LocalBitFlipGOF < LocalGenRRGOF; the bigger $\\varepsilon$  privacy parameter the bigger power of test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](pictures/results.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also we measured time dependence for varios d and n. But in LocalGenRRGOF and LocalBitFlipGOF we utilize python loops for perturbing procedure of samples, because of that our experiments are not really honest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$d$ = 4\n",
    "![title](pictures/time_n.png)\n",
    "![title](pictures/time_n_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$n$ = 1000\n",
    "![title](pictures/time_d.png)\n",
    "![title](pictures/time_d_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see than non-private test is much faster than private tests, for example in 10000 times in case $d=4$, $n =20000.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $$Conclusion$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we tried to implement algorithms 6 and 7 we faced some problems. Algorithm 6, for example, is designed to check hypotesis about parameter $ p $, but according to the description it should use statistic $\\mathcal{T^{(n)}_{GenRR}}$ which is defined for independence test.\n",
    "![title](pictures/alg6.png)\n",
    "\n",
    "![title](pictures/tau_gen.png)\n",
    "And similar problems appeared with algorithm 7. Unfortunately, we didn't have enough time to resolve these issues.\n",
    "\n",
    "Also we didn't clearly got the setting for experiments with non-central parameters comparisson. There is no setting for $\\Delta$ in article, also it is not clear what is shown on the graphics. Did the authors sample from $\\mathcal{T}^{(n)}_{GenRR}(\\varepsilon), \\mathcal{T}^{(n)}_{BitFlip}(\\varepsilon)$ to estimate noncentral parameter? How did they estimate it? Did they check that distribution is noncentral $\\chi^2$ or did they just plot assymptotic dependence they proved in theorems? These questions, unfortunately, remained unanswered due to the lack of information in the article."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "Here is the list of the results we achieved and found out while working on this project:\n",
    "- Results for experiments about power test coincide with results in the article.\n",
    "- LocalGenRRGOF shows more accurate results than LocalBitFlipGOF and LocalNoiseGOF tests.\n",
    "- Privacy test are much more computationally expensive then non-private test.\n",
    "- If we increase the test's level of privacy then we lose in its power."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $$Contributions$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main part of the algorithms were created by Alexander Telepov. Tests and calculus were performed by Maksim Pankratov and Julia Moroz. We all worked by our presentation and text."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
